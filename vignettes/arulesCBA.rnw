\documentclass[nojss]{jss}

\usepackage{Sweave}
%\VignetteIndexEntry{Introduction to arulesCBA}

\author{Ian Johnson\\Southern Methodist University}
\title{\pkg{arulesCBA}:  Classification for Factor and Transactional Data Sets Using Association Rules }

\Plainauthor{Ian Johnson}
\Plaintitle{arulesCBA:  Classification for Factor and Transactional Data Sets Using Association Rules}

\Abstract{
  This paper presents an \proglang{R} package, \pkg{arulesCBA}, which uses association rules mined with the apriori algorithm from \pkg{arules} to build a classifier for discrete or transactional data sets. The package also provides an interface to use an association-rule classifier to predict classes for new data entries. The classification algorithm implemented in \pkg{arulesCBA} performs competitively when compared to existing discrete classification algorithms.
}
\Keywords{data mining, classification, association rules, \proglang{R}}
\Plainkeywords{data mining, classification, association rules, R}
\Address{
  Ian Johnson\\
  Computer Science and Engineering\\
  Southern Methodist University\\
  Dallas, Texas\\
  E-mail: \email{ianjjohnson@icloud.com}\\
  URL: \url{http://www.ianjjohnson.com}
}



\begin{document}
\SweaveOpts{concordance=TRUE}


\section[Introduction]{Introduction}

Association rule mining is a well-established strategy for discovering relationships among attributes of discrete, factor, and transactional data sets. Existing \proglang{R} packages such as \pkg{arules} provide interfaces to \proglang{C} implementations of fast association rule mining algorithms such as apriori.
%For an in-depth description of association rule mining, its purpose, and the statistical theory behind it, see \cite{}.
For the purpose of this paper, association rule mining will be treated as a black box, as association rules for the classification algorithm in \pkg{arulesCBA} will be mined using the apriori interface in \pkg{arules}. The rules mined from the algorithm will have five relevant fields. The first three: lift, support, and confidence, are statistical measures of the strength of an association rule which will be discussed in later sections. The final attributes of an association rule are the predicate, or left-hand-side of the rule, and the class, or the right-hand-side of the rule. The predicate of a rule is the set of elements in a row of data which are associated with the resulting class of the rule. The classification algorithm in \pkg{arulesCBA} uses a special type of association rule where the right-hand-side is a set of size one (called a class). These rules are called CARs (Class Association Rules). The remainder of the paper will be organized as follows: first, the \proglang{R} interface of the \pkg{arulesCBA} will be explored, then the CBA algorithm will be detailed, and then an example of using the \pkg{arulesCBA} interface to classify the \code{Iris} data set from the \proglang{R} package \pkg{datasets} will be provided.

\section[Interface]{The arulesCBA Interface}
The \pkg{arulesCBA} package provides four user-facing functions: \code{CBA}, \code{predict}, \code{rules}, and \code{print}. The functions \code{rules} and \code{print} functions simply return the rules of a CBA classifier object and print the important information about a CBA object, respectively. The \code{CBA} and \code{predict} functions are used to build a classifier from an existing data set, and to predict classes for an incoming data set, respectively.

\subsection[CBA]{The CBA Function}
The function \code{CBA} provides an \proglang{R} interface to a \proglang{C} implementation of the CBA algorithm used to generate a classifier. The function accepts two required arguments, and three option arguments. The required arguments, \code{data} and \code{class}, must contain the data set for which a classifier will be built, and a character vector with the name of the column of the data set which will be used as the class variable. The argument \code{data} must be a data.frame or a transaction matrix from the \pkg{arules} package, and it must include a column whose name is equal to the argument \code{class}.

The optional arguments, \code{support}, \code{confidence}, and \code{verbose}, are used to provide parameters to the \code{apriori} interface from the \pkg{arules} package. The argument \code{support}, set to 0.2 by default, is used to set a minimum support value for the association rules mined from \code{apriori}. Likewise, the argument \code{confidence}, set to 0.8 by default, is used to set a minimum confidence value for the association rules mined from \code{apriori}. Finally, the \code{verbose} argument, set to \code{FALSE} by default, can be used to print out diagnostic run-time information from within the \code{CBA} and \code{apriori} functions.

The following are an examples of valid calls to the \textit{CBA} function:

\code{
> classifier <- CBA(formula, data) \\
> classifier <- CBA(formula data, confidence = 0.95, verbose = TRUE)
}

These are only valid calls to the \textit{CBA} function if the following conditions are met:

\begin{itemize}
\item{The object \code{formula} contains a symbolic description of the model to be fitted. The only model type currently supported is of the from \code{class ~ .}, where \code{class} is the name of the class variable.}
\item{The object \code{data} is a data.frame whose columns are all factors, or an \pkg{arules} transaction object.}
\item{The column in \code{date} representing the class is not allowed to have missing values.}
\end{itemize}

The object returned by the CBA function is a CBA object, which is a list with three elements: \code{rules}, \code{default}, and \code{levels}. The object \code{rules} is an ordered vector of \pkg{arules} association rules which are used for classification. The object \code{default} is a character vector of size 1 which holds the default class for the classifier, which will be discussed in later sections. Finally, \code{levels} is a vector of all of the possible classes for an object being sent to the classifier.

The \code{rules} object can be extracted from the \code{CBA} object using the function \code{rules(CBA)}. The \code{default} and \code{levels} objects are only used internally in the \code{predict} function.

\subsection[predict]{The Predict Function}
The function \code{predict} is used to apply a CBA classifier to a new set of data to be classified. The function accepts only two arguments, \code{object} and \code{newdata}, which are the CBA object and the new data set to be classified, respectively. The CBA classifier \code{object} can be sent to \code{predict} directly from the \code{CBA} function. The \code{newdata} object must be a data.frame or \pkg{arules} transaction object whose columns match those used to build the original classifier.

The following is an example of a valid call to the \code{predict} function, where a data.frame \code{dataset} is split into \code{training} and \code{testing} sets which are used to build a CBA classifier, and then use it, respectively:

\code{
> className <- colnames(data)[1] \\
> training <- data[1:750,] \\
> testing <- data[751, 1000] \\
> classifier <- CBA(training, className) \\
> classes <- predict(classifier, testing)
}

This is correct use of the \textit{predict} function if all conditions are met for the \code{CBA} function, where in this example \code{dataset} is a data.frame. After executing this code, the objects \code{classes} and \code{data[,1]} should be similar, or exactly the same if the classifier worked with 100\% accuracy. A cursory examination of the success of the prediction can be done using \code{table(classes)} and \code{table(data[,1])}. A more in-depth comparison can be done by computing a confusion matrix.

\section[algorithm]{The CBA Algorithm}
The CBA (Classification Based on Association rules) algorithm used in \pkg{arulesCBA} is adapted from \textit{Liu, et al., 1998}. The algorithm is split up into three stages, each of which is implemented in \proglang{C} and interfaced from \proglang{R} through \pkg{arulesCBA}. The non-performance-critical and data formatting operations are completed in \proglang{R}, while performance-critical operations take place in \proglang{C}.

\subsection[stage0]{Stage 0}
Prior to the three stages of the CBA algorithm, a number of preconditions must be met. Prior to stage 1 of the algorithm, therefore, a stage 0 occurs to establish those preconditions. First, a set of association rules must be generated. This is completed using a call to \code{apriori} from \pkg{arules}. These rules are then sorted primarily based on their \textit{confidence}, and then by their \textit{support} and \textit{lift}. \textit{Confidence} is a measure of how frequently the predicate of an association rule correctly predicts the class of a data entry. For a rule whose predicate predicts the class in every case, the \textit{confidence} value is 1. It is therefore the primary tool for ranking association rules for use in a classifier.	 Generating association rules, and sorting them as described above, is achieved as follows:

\code{
> rules <- apriori(ds.mat, \textit{...}) \\
> rules.sorted <- sort(rules, by=c("confidence", "support", "lift"))
}

Note that the call to \code{apriori} includes a number of additional parameters to guarantee that the mined rules will be useful for the classifier, but those parameters have been redacted for simplicity.

The data input to the classifier must also be formatted as an \pkg{arules} transaction object, and two matrices are constructed, \code{rulesMatchLHS} and \code{rulesMatchRHS}, which identify which rules from the mined ruleset correspond to the predicate and class of which data entries in the input data set. The matrices are generated as follows:

\code{
> rulesMatchLHS <- is.subset(lhs(rules.sorted), ds.mat) \\
> rulesMatchRHS <- is.subset(rhs(rules.sorted), ds.mat) \\
  }

In this version of \pkg{arulesCBA}, dense matrices are used for rulesMatchLHS and rulesMatchRHS. Future versions will use sparse matrices for memory efficiency.

A number of other data structures are instantiated and organized for later use, but their purpose, while critical to functionality, is not critical to understanding the algorithm, and they have therefore been omitted from this description of the algorithm. This description of the CBA algorithm is simplified considerably for the sake of clarity. It provides more than enough information to be able to use the \pkg{arulesCBA} interface confidently.

\subsection[stage1]{Stage 1}
In stage 1 of the CBA algorithm, a linear pass is made through the entire input data set, and a set \code{A} is built of all falsely classified record. A falsely classified record is one which matches the left-hand-side of a rule in the classifier but whose class doesn't match the right-hand-side of that rule. Each falsely classified record in \code{A} is stored alongside a corresponding \textit{crule} and \textit{wrule} for the record. A \textit{crule} (correct rule) is a rule which matches an entry on both the left and right-hand-sides of the rule, while a \textit{wrule} (wrong rule) is a rule which matches an entry on the left-hand-side, but not the right-hand-side. Stage 1 of the algorithm also builds a list of \textit{strong rules}, rules which correctly identify entries in the input data set and will therefore be used in the final classifier.

\subsection[stage2]{Stage 2}
Stage 2 of the CBA processes the set \code{A} to find possible replacement rules for the \textit{wrules} which falsely classified records. This stage performs a linear pass through \code{A}, a subset of the input data set. For each element in \code{A}, a list of possible replacement rules for the \textit{crule} identified is generated and added to a new set, \code{replace}, which will be used in stage 3. A possible replacement rule is defined as any rule which correctly classifies the data entry in question.

\subsection[stage3]{Stage 3}
In stage 3, the final stage of the CBA algorithm, the set \code{replace} is processed, and a final classifier is built. A linear pass is made through the set of association rules which have been labeled as \textit{strong rules}. For each rule, all possible replacement rules identified in \code{replace} are evaluated for possible replacement. If the replacement rules correctly classify a record, they are prioritized over the rule to be replaced. As the set is processed, information is maintained about how many elements from the original data set are correctly and incorrectly classified by the set of already-processed rules. At each rule, the number of falsely classified records is stored in a set \code{totalErrors}. After every rule has been processed, the classifier is built as the subset of the original rule set up to the index of the minimum number of class errors in the \code{totalErrors} set. This classifier is then returned with a default class via the \proglang{R} interface in \pkg{arulesCBA}.

\section[example]{Using arulesCBA}
The following is an example of how \pkg{arulesCBA} can be used to classify flowers from the \code{Iris} data set in the \pkg{datasets} package. The \code{Iris} data set is a set of 150 observations of 5 variables. The first 4 variables are continuous measures of petal and sepal length of flowers. The 5th variable is the species of the flower. This will be used as the class for the classification process.

\subsection[install]{Installing arulesCBA}

Prior to executing the following example, install \pkg{arulesCBA} using:
 \code{install.packages("arulesCBA")}\\

To install the most recent development version, use:
 \code{> install_github("ianjjohnson/arulesCBA")}. \\

 \code{install_github} is available through the \pkg{devtools} package.

\subsection[libs]{Loading Required Packages}
To load the \pkg{arulesCBA} package, as well as the \pkg{caret} package, which is used for assessing the results of the classifier, use:

<<echo=FALSE>>=
options(digits=2)
@

<<>>=
library(arulesCBA)
@

Note that the package \pkg{caret} can be installed using \code{install.packages(caret)}.

\subsection[disc]{Discretizing the Data}

arulesCBA now performs discretization within the CBA and bCBA functions. Custom discretization can be used, but most state-of-the art class-based discretization strategies are already supported. Discretization method can be specified using the disc.method parameter to CBA or bCBA.

<<echo=TRUE>>=
data(iris)
@

\subsection[cba]{Building the Classifier}
Building the classifier can be done with a simple call to the \code{CBA} function:

<<echo=TRUE>>=
classifier <- CBA(Species ~ ., iris, supp = 0.05, conf=0.9)
@

Note that the second parameter to the \code{CBA} function, \code{class}, is the name of the column of \code{iris.disc} which contains the class of each entry. Also recall that the \code{iris.disc} data must be convertible to \pkg{arules} transaction data at this point in execution.

Basic information about the classifier can be found using the \code{print} function:

<<echo=TRUE>>=
classifier
@


\subsection[rules]{Accessing the Rules of the Classifier}

The rules as an arules rule list can be retreived using:

<<echo=TRUE>>=
rules(classifier)
@

The association rules of the classifier can be read found seen using:

<<echo=TRUE>>=
inspect(rules(classifier))
@

\subsection[predict]{Using the Classifier}
Once the classifier has been built, it can be used to classify the training data set as a cursory test of its accuracy using a simple call to \code{predict}:

<<echo=TRUE>>=
pred <- predict(classifier, iris)
@

<<echo=TRUE>>=
head(pred)
table(pred)
@

This table shows that the \pkg{arulesCBA} classifier predicted that there is a 50-48-52 split of the 3 species in the test data.

\subsection[results]{Checking the Results}
In order to ascertain the quality of the predicted classes,
we can create a simple confusion matrix:

<<echo=TRUE>>=
table(pred, truth = iris$Species)
@

More sophisticated confusion matrices can be created using packages like
\pkg{caret} or  \pkg{gmodels}.

\end{document}
